{
    "cells": [
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "7b5d30a7",
                "execution_start": 1747947088342,
                "execution_millis": 250871,
                "execution_context_id": "6d1cdcae-86ca-4db9-9228-9d6382a45c48",
                "deepnote_to_be_reexecuted": true,
                "cell_id": "55a59d16fcdf4e49a35d38570b977f2f",
                "deepnote_cell_type": "code"
            },
            "source": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n/fiap/cap14/modelos_preditivos.py\n\nScript para desenvolvimento de modelos preditivos para recomendação\nde culturas agrícolas com base em condições de solo e clima\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport time\nimport joblib\n\n# Bibliotecas para ML\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score,\n                           f1_score, classification_report, confusion_matrix,\n                           matthews_corrcoef, balanced_accuracy_score)\nfrom sklearn.pipeline import Pipeline\n\n# Algoritmos\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\n# Bibliotecas para visualização\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.colors import LinearSegmentedColormap\nimport matplotlib.patches as mpatches\n\n# Configurações de visualização\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set(font_scale=1.1)\nplt.rcParams['figure.figsize'] = (12, 8)\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.titlesize'] = 14\nplt.rcParams['xtick.labelsize'] = 10\nplt.rcParams['ytick.labelsize'] = 10\n\n# Definir caminhos\nDATA_DIR = Path('fase3_cap14/src/datasets/')\nDATASET_PATH = DATA_DIR / 'Atividade_Cap_14_produtos_agricolas.csv'\nOUTPUT_DIR = Path('fase3_cap14/src/datasets/output/modelos_preditivos/modelos')\nOUTPUT_DIR.mkdir(exist_ok=True)\nFIGURES_DIR = Path('fase3_cap14/src/datasets/output/modelos_preditivos/figuras')\nFIGURES_DIR.mkdir(exist_ok=True)\n\n# Cores personalizadas para visualizações\nCUSTOM_COLORS = [\n    \"#4E79A7\", \"#F28E2B\", \"#E15759\", \"#76B7B2\", \"#59A14F\",\n    \"#EDC948\", \"#B07AA1\", \"#FF9DA7\", \"#9C755F\", \"#BAB0AC\"\n]\n\n# Configurar seed para reprodutibilidade\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\n# Definir modelos a serem testados\nMODELOS = {\n    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n    'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE),\n    'SVM': SVC(random_state=RANDOM_STATE, probability=True),\n    'KNN': KNeighborsClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE)\n}\n\nclass AgricultureMLPipeline:\n    \"\"\"\n    Pipeline para desenvolvimento e avaliação de modelos de ML\n    para recomendação de culturas agrícolas\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Inicializa o pipeline de ML\n        \"\"\"\n        self.df = None\n        self.X_train = None\n        self.X_test = None\n        self.y_train = None\n        self.y_test = None\n        self.feature_names = None\n        self.target_encoder = None\n        self.models = {}\n        self.results = {}\n        self.best_model = None\n        self.best_model_name = None\n\n    def carregar_dados(self):\n        \"\"\"\n        Carrega os dados do dataset\n        \"\"\"\n        try:\n            self.df = pd.read_csv(DATASET_PATH)\n            print(f\"Dataset carregado com sucesso: {self.df.shape[0]} linhas e {self.df.shape[1]} colunas\")\n            return True\n        except Exception as e:\n            print(f\"Erro ao carregar o dataset: {e}\")\n            return False\n\n    def explorar_dados(self):\n        \"\"\"\n        Realiza exploração básica dos dados\n        \"\"\"\n        print(\"\\n===== Exploração dos Dados =====\")\n\n        # Informações básicas\n        print(\"\\nInformações do dataset:\")\n        print(self.df.info())\n\n        print(\"\\nEstatísticas descritivas:\")\n        print(self.df.describe())\n\n        # Verificar valores ausentes\n        missing_values = self.df.isnull().sum()\n        if missing_values.sum() > 0:\n            print(\"\\nValores ausentes:\")\n            print(missing_values[missing_values > 0])\n        else:\n            print(\"\\nNão foram encontrados valores ausentes no dataset.\")\n\n        # Distribuição da variável alvo\n        print(\"\\nDistribuição da variável alvo (culturas):\")\n        target_counts = self.df['label'].value_counts()\n        print(target_counts)\n\n        # Verificar balanceamento das classes\n        print(f\"\\nNúmero total de classes: {len(target_counts)}\")\n        print(f\"Classe mais frequente: {target_counts.index[0]} ({target_counts.iloc[0]} ocorrências)\")\n        print(f\"Classe menos frequente: {target_counts.index[-1]} ({target_counts.iloc[-1]} ocorrências)\")\n\n        # Plotar distribuição das classes\n        plt.figure(figsize=(10, 6))\n        ax = sns.countplot(y='label', data=self.df, order=target_counts.index)\n        plt.title('Distribuição das Culturas no Dataset', fontsize=14)\n        plt.xlabel('Contagem', fontsize=12)\n        plt.ylabel('Cultura', fontsize=12)\n        # Adicionar rótulos de contagem\n        for i, count in enumerate(target_counts):\n            ax.text(count + 1, i, f\"{count}\", va='center')\n        plt.tight_layout()\n        plt.savefig(FIGURES_DIR / 'distribuicao_culturas.png', dpi=300)\n        plt.close()\n\n        return target_counts\n\n    def preprocessar_dados(self, test_size=0.2, scale_features=True):\n        \"\"\"\n        Realiza o pré-processamento dos dados e divisão em treino/teste\n        \"\"\"\n        print(\"\\n===== Pré-processamento dos Dados =====\")\n\n        # Separar features e target\n        X = self.df.drop('label', axis=1)\n        y = self.df['label']\n\n        # Salvar nomes das features\n        self.feature_names = X.columns.tolist()\n\n        # Codificar a variável alvo\n        self.target_encoder = LabelEncoder()\n        y_encoded = self.target_encoder.fit_transform(y)\n\n        # Mapear classes para facilitar a interpretação\n        self.target_mapping = dict(zip(self.target_encoder.transform(self.target_encoder.classes_),\n                                    self.target_encoder.classes_))\n\n        # Dividir em conjuntos de treino e teste\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n            X, y_encoded, test_size=test_size, random_state=RANDOM_STATE, stratify=y_encoded\n        )\n\n        print(f\"Dados divididos em {self.X_train.shape[0]} amostras de treino e {self.X_test.shape[0]} amostras de teste\")\n\n        # Escalar as features se solicitado\n        if scale_features:\n            scaler = StandardScaler()\n            self.X_train = scaler.fit_transform(self.X_train)\n            self.X_test = scaler.transform(self.X_test)\n            print(\"Features normalizadas utilizando StandardScaler\")\n\n        # Verificar balanceamento nos conjuntos de treino e teste\n        train_counts = np.bincount(self.y_train)\n        test_counts = np.bincount(self.y_test)\n\n        print(f\"Distribuição de classes no conjunto de treino: Min={min(train_counts)}, Max={max(train_counts)}\")\n        print(f\"Distribuição de classes no conjunto de teste: Min={min(test_counts)}, Max={max(test_counts)}\")\n\n        return True\n\n    def treinar_modelos(self):\n        \"\"\"\n        Treina os cinco modelos diferentes\n        \"\"\"\n        print(\"\\n===== Treinamento dos Modelos =====\")\n\n        self.models = {}\n        self.training_times = {}\n\n        for nome, modelo in MODELOS.items():\n            print(f\"\\nTreinando modelo: {nome}\")\n            inicio = time.time()\n\n            # Treinar o modelo\n            modelo.fit(self.X_train, self.y_train)\n\n            # Salvar modelo e tempo de treinamento\n            self.models[nome] = modelo\n            tempo_treino = time.time() - inicio\n            self.training_times[nome] = tempo_treino\n\n            print(f\"Modelo {nome} treinado em {tempo_treino:.2f} segundos\")\n\n            # Salvar modelo em disco\n            joblib.dump(modelo, OUTPUT_DIR / f\"{nome.replace(' ', '_').lower()}_model.pkl\")\n\n        return self.models\n\n    def otimizar_hiperparametros(self):\n        \"\"\"\n        Otimiza os hiperparâmetros dos modelos utilizando GridSearchCV\n        \"\"\"\n        print(\"\\n===== Otimização de Hiperparâmetros =====\")\n\n        # Definir parâmetros para busca (grids)\n        param_grids = {\n            'Decision Tree': {\n                'criterion': ['gini', 'entropy'],\n                'max_depth': [None, 10, 20, 30],\n                'min_samples_split': [2, 5, 10],\n                'min_samples_leaf': [1, 2, 4]\n            },\n            'Random Forest': {\n                'n_estimators': [50, 100, 200],\n                'max_depth': [None, 10, 20, 30],\n                'min_samples_split': [2, 5, 10],\n                'min_samples_leaf': [1, 2, 4]\n            },\n            'SVM': {\n                'C': [0.1, 1, 10, 100],\n                'gamma': ['scale', 'auto', 0.1, 0.01],\n                'kernel': ['rbf', 'linear']\n            },\n            'KNN': {\n                'n_neighbors': [3, 5, 7, 9, 11],\n                'weights': ['uniform', 'distance'],\n                'p': [1, 2]  # 1 para distância Manhattan e 2 para Euclidiana\n            },\n            'Gradient Boosting': {\n                'n_estimators': [50, 100, 200],\n                'learning_rate': [0.01, 0.1, 0.2],\n                'max_depth': [3, 5, 7],\n                'min_samples_split': [2, 5]\n            }\n        }\n\n        self.best_models = {}\n\n        for nome, modelo in MODELOS.items():\n            print(f\"\\nOtimizando hiperparâmetros para: {nome}\")\n\n            # Criar GridSearchCV\n            grid_search = GridSearchCV(\n                estimator=modelo,\n                param_grid=param_grids[nome],\n                cv=5,  # 5-fold cross-validation\n                scoring='accuracy',\n                n_jobs=-1,  # Usar todos os núcleos disponíveis\n                verbose=1\n            )\n\n            # Executar busca\n            inicio = time.time()\n            grid_search.fit(self.X_train, self.y_train)\n            tempo = time.time() - inicio\n\n            # Salvar melhor modelo\n            self.best_models[nome] = grid_search.best_estimator_\n\n            print(f\"Melhores parâmetros para {nome}: {grid_search.best_params_}\")\n            print(f\"Melhor score de validação cruzada: {grid_search.best_score_:.4f}\")\n            print(f\"Tempo de otimização: {tempo:.2f} segundos\")\n\n            # Salvar melhor modelo em disco\n            joblib.dump(grid_search.best_estimator_,\n                      OUTPUT_DIR / f\"{nome.replace(' ', '_').lower()}_best_model.pkl\")\n\n        return self.best_models\n\n    def avaliar_modelos(self, use_best_models=True):\n        \"\"\"\n        Avalia o desempenho dos modelos no conjunto de teste\n        \"\"\"\n        print(\"\\n===== Avaliação dos Modelos =====\")\n\n        self.results = {}\n\n        # Escolher quais modelos avaliar (básicos ou otimizados)\n        modelos_avaliar = self.best_models if use_best_models else self.models\n\n        for nome, modelo in modelos_avaliar.items():\n            print(f\"\\nAvaliando modelo: {nome}\")\n\n            # Fazer previsões\n            inicio = time.time()\n            y_pred = modelo.predict(self.X_test)\n            tempo_inferencia = time.time() - inicio\n\n            # Calcular métricas\n            acc = accuracy_score(self.y_test, y_pred)\n            balanced_acc = balanced_accuracy_score(self.y_test, y_pred)\n            precision = precision_score(self.y_test, y_pred, average='weighted')\n            recall = recall_score(self.y_test, y_pred, average='weighted')\n            f1 = f1_score(self.y_test, y_pred, average='weighted')\n            mcc = matthews_corrcoef(self.y_test, y_pred)\n\n            # Armazenar resultados\n            self.results[nome] = {\n                'accuracy': acc,\n                'balanced_accuracy': balanced_acc,\n                'precision': precision,\n                'recall': recall,\n                'f1_score': f1,\n                'matthews_corrcoef': mcc,\n                'inference_time': tempo_inferencia\n            }\n\n            # Imprimir resultados principais\n            print(f\"Acurácia: {acc:.4f}\")\n            print(f\"Acurácia Balanceada: {balanced_acc:.4f}\")\n            print(f\"Precisão: {precision:.4f}\")\n            print(f\"Recall: {recall:.4f}\")\n            print(f\"F1-Score: {f1:.4f}\")\n            print(f\"Coeficiente de Matthews: {mcc:.4f}\")\n            print(f\"Tempo de inferência: {tempo_inferencia:.6f} segundos\")\n\n            # Gerar relatório de classificação detalhado\n            print(\"\\nRelatório de classificação detalhado:\")\n            class_report = classification_report(\n                self.y_test,\n                y_pred,\n                target_names=self.target_encoder.classes_\n            )\n            print(class_report)\n\n            # Gerar e salvar matriz de confusão\n            self._gerar_matriz_confusao(\n                self.y_test,\n                y_pred,\n                nome,\n                self.target_encoder.classes_\n            )\n\n        # Identificar o melhor modelo\n        self._identificar_melhor_modelo()\n\n        return self.results\n\n    def _identificar_melhor_modelo(self):\n        \"\"\"\n        Identifica o melhor modelo com base no F1-Score\n        \"\"\"\n        # Ordenar modelos por F1-Score\n        modelos_ordenados = sorted(\n            self.results.items(),\n            key=lambda x: x[1]['f1_score'],\n            reverse=True\n        )\n\n        self.best_model_name = modelos_ordenados[0][0]\n        self.best_model = self.best_models[self.best_model_name]\n\n        print(f\"\\nMelhor modelo: {self.best_model_name}\")\n        print(f\"F1-Score: {self.results[self.best_model_name]['f1_score']:.4f}\")\n\n        return self.best_model_name\n\n    def _gerar_matriz_confusao(self, y_true, y_pred, model_name, class_names):\n        \"\"\"\n        Gera e salva a matriz de confusão para um modelo\n        \"\"\"\n        # Calcular matriz de confusão\n        cm = confusion_matrix(y_true, y_pred)\n\n        # Normalizar matriz (opcional para melhor visualização)\n        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n        # Criar figura\n        plt.figure(figsize=(12, 10))\n\n        # Plotar matriz de confusão\n        sns.heatmap(\n            cm_norm,\n            annot=True,\n            fmt=\".2f\",\n            cmap=\"Blues\",\n            xticklabels=class_names,\n            yticklabels=class_names\n        )\n\n        plt.title(f'Matriz de Confusão Normalizada - {model_name}', fontsize=16)\n        plt.ylabel('Classe Real', fontsize=14)\n        plt.xlabel('Classe Prevista', fontsize=14)\n        plt.tight_layout()\n\n        # Salvar figura\n        plt.savefig(\n            FIGURES_DIR / f'confusion_matrix_{model_name.replace(\" \", \"_\").lower()}.png',\n            dpi=300\n        )\n        plt.close()\n\n    def comparar_modelos(self):\n        \"\"\"\n        Compara o desempenho dos modelos visualmente\n        \"\"\"\n        print(\"\\n===== Comparação de Modelos =====\")\n\n        # Preparar dados para visualização\n        modelos = list(self.results.keys())\n        metricas = ['accuracy', 'balanced_accuracy', 'precision',\n                   'recall', 'f1_score', 'matthews_corrcoef']\n\n        # Criar DataFrame com resultados\n        resultados_df = pd.DataFrame({\n            'Modelo': [],\n            'Métrica': [],\n            'Valor': []\n        })\n\n        for modelo in modelos:\n            for metrica in metricas:\n                resultados_df = pd.concat([resultados_df, pd.DataFrame({\n                    'Modelo': [modelo],\n                    'Métrica': [metrica],\n                    'Valor': [self.results[modelo][metrica]]\n                })], ignore_index=True)\n\n        # Criar gráfico de barras para comparação\n        plt.figure(figsize=(14, 10))\n        sns.barplot(\n            data=resultados_df,\n            x='Métrica',\n            y='Valor',\n            hue='Modelo',\n            palette=CUSTOM_COLORS[:len(modelos)]\n        )\n\n        plt.title('Comparação de Performance entre Modelos', fontsize=16)\n        plt.xlabel('Métrica', fontsize=14)\n        plt.ylabel('Valor', fontsize=14)\n        plt.ylim(0, 1)\n        plt.xticks(rotation=45)\n        plt.legend(title='Modelo', loc='lower right')\n        plt.grid(axis='y', alpha=0.3)\n        plt.tight_layout()\n\n        plt.savefig(FIGURES_DIR / 'comparacao_modelos.png', dpi=300)\n        plt.close()\n\n        # Criar tabela de resultados\n        tabela_resultados = pd.DataFrame()\n\n        for modelo in modelos:\n            tabela_resultados[modelo] = pd.Series({\n                'Acurácia': self.results[modelo]['accuracy'],\n                'Acurácia Balanceada': self.results[modelo]['balanced_accuracy'],\n                'Precisão': self.results[modelo]['precision'],\n                'Recall': self.results[modelo]['recall'],\n                'F1-Score': self.results[modelo]['f1_score'],\n                'Coef. Matthews': self.results[modelo]['matthews_corrcoef'],\n                'Tempo Inferência (s)': self.results[modelo]['inference_time']\n            })\n\n        # Salvar tabela\n        tabela_resultados.to_csv(OUTPUT_DIR / 'comparacao_modelos.csv')\n\n        print(\"\\nTabela comparativa de modelos:\")\n        print(tabela_resultados)\n\n        return tabela_resultados\n\n    def analisar_importancia_features(self):\n        \"\"\"\n        Analisa a importância das features para os modelos que suportam\n        essa funcionalidade (Decision Tree, Random Forest, Gradient Boosting)\n        \"\"\"\n        print(\"\\n===== Análise de Importância de Features =====\")\n\n        # Modelos que suportam importância de features\n        modelos_suportados = [\n            'Decision Tree',\n            'Random Forest',\n            'Gradient Boosting'\n        ]\n\n        importancias = {}\n\n        # Coletar importância de features dos modelos\n        for nome in modelos_suportados:\n            if nome in self.best_models:\n                modelo = self.best_models[nome]\n\n                # Extrair importância de features\n                if hasattr(modelo, 'feature_importances_'):\n                    importancias[nome] = dict(zip(\n                        self.feature_names,\n                        modelo.feature_importances_\n                    ))\n\n                    # Ordenar features por importância\n                    importancias[nome] = dict(sorted(\n                        importancias[nome].items(),\n                        key=lambda x: x[1],\n                        reverse=True\n                    ))\n\n                    print(f\"\\nImportância de features para {nome}:\")\n                    for feature, imp in importancias[nome].items():\n                        print(f\"  {feature}: {imp:.4f}\")\n\n        # Visualizar importância de features\n        if importancias:\n            self._visualizar_importancia_features(importancias)\n\n        return importancias\n\n    def _visualizar_importancia_features(self, importancias):\n        \"\"\"\n        Cria visualizações para importância de features\n        \"\"\"\n        for nome, imp in importancias.items():\n            # Converter para DataFrame e ordenar\n            df_imp = pd.DataFrame({\n                'Feature': list(imp.keys()),\n                'Importância': list(imp.values())\n            }).sort_values('Importância', ascending=False)\n\n            # Plotar gráfico de barras horizontais\n            plt.figure(figsize=(10, 8))\n            sns.barplot(\n                data=df_imp,\n                y='Feature',\n                x='Importância',\n                palette='viridis'\n            )\n\n            plt.title(f'Importância de Features - {nome}', fontsize=14)\n            plt.xlabel('Importância', fontsize=12)\n            plt.ylabel('Feature', fontsize=12)\n            plt.tight_layout()\n\n            plt.savefig(\n                FIGURES_DIR / f'feature_importance_{nome.replace(\" \", \"_\").lower()}.png',\n                dpi=300\n            )\n            plt.close()\n\n    def extrair_regras_decision_tree(self):\n        \"\"\"\n        Extrai regras interpretáveis da Decision Tree\n        \"\"\"\n        if 'Decision Tree' not in self.best_models:\n            print(\"Modelo Decision Tree não disponível para extração de regras.\")\n            return None\n\n        print(\"\\n===== Extração de Regras da Decision Tree =====\")\n\n        tree_model = self.best_models['Decision Tree']\n\n        # Extrair regras da árvore usando o método auxiliar\n        from sklearn.tree import export_text\n\n        regras = export_text(\n            tree_model,\n            feature_names=self.feature_names,\n            max_depth=3,  # Limitar profundidade para facilitar interpretação\n            decimals=2\n        )\n\n        print(\"\\nRegras extraídas da Decision Tree (limitadas à profundidade 3):\")\n        print(regras)\n\n        # Salvar regras em um arquivo\n        with open(OUTPUT_DIR / 'decision_tree_rules.txt', 'w') as f:\n            f.write(regras)\n\n        return regras\n\n    def gerar_exemplos_praticos(self):\n        \"\"\"\n        Gera exemplos práticos de previsões usando o melhor modelo\n        \"\"\"\n        print(\"\\n===== Exemplos Práticos de Previsões =====\")\n\n        if not self.best_model:\n            print(\"Nenhum modelo identificado como o melhor.\")\n            return\n\n        # Selecionar alguns exemplos reais do conjunto de teste\n        indices = np.random.choice(len(self.X_test), 5, replace=False)\n        X_exemplos = self.X_test[indices]\n        y_real = self.y_test[indices]\n\n        # Fazer previsões com o melhor modelo\n        y_pred = self.best_model.predict(X_exemplos)\n\n        # Se o modelo suporta probabilidades, extrair também\n        if hasattr(self.best_model, 'predict_proba'):\n            y_proba = self.best_model.predict_proba(X_exemplos)\n            probabilidades = np.max(y_proba, axis=1)\n        else:\n            probabilidades = [None] * len(y_pred)\n\n        # Converter índices previstos para nomes de culturas\n        culturas_reais = [self.target_mapping[y] for y in y_real]\n        culturas_previstas = [self.target_mapping[y] for y in y_pred]\n\n        # Mostrar resultados\n        print(f\"\\nExemplos de previsões utilizando o modelo {self.best_model_name}:\")\n\n        for i in range(len(X_exemplos)):\n            print(f\"\\nExemplo {i+1}:\")\n\n            # Converter vetor de features para dicionário com nomes\n            if isinstance(X_exemplos[i], np.ndarray):\n                features = dict(zip(self.feature_names, X_exemplos[i]))\n            else:\n                features = X_exemplos[i]\n\n            for feat, val in features.items():\n                print(f\"  {feat}: {val:.2f}\")\n\n            print(f\"  Cultura real: {culturas_reais[i]}\")\n            print(f\"  Cultura prevista: {culturas_previstas[i]}\")\n\n            if probabilidades[i] is not None:\n                print(f\"  Confiança da previsão: {probabilidades[i]:.2f}\")\n\n            # Indicar se a previsão está correta\n            print(f\"  Previsão correta: {'Sim' if culturas_reais[i] == culturas_previstas[i] else 'Não'}\")\n\n        return {'X_exemplos': X_exemplos, 'y_real': culturas_reais,\n               'y_pred': culturas_previstas, 'proba': probabilidades}\n\n    def executar_pipeline_completo(self):\n        \"\"\"\n        Executa o pipeline completo de ML\n        \"\"\"\n        print(\"\\n===== Iniciando Pipeline Completo de ML =====\")\n\n        # Etapa 1: Carregar dados\n        if not self.carregar_dados():\n            return \"Falha ao carregar os dados. Pipeline interrompido.\"\n\n        # Etapa 2: Explorar dados\n        self.explorar_dados()\n\n        # Etapa 3: Pré-processar dados\n        self.preprocessar_dados()\n\n        # Etapa 4: Treinar modelos básicos\n        self.treinar_modelos()\n\n        # Etapa 5: Otimizar hiperparâmetros\n        self.otimizar_hiperparametros()\n\n        # Etapa 6: Avaliar modelos otimizados\n        self.avaliar_modelos(use_best_models=True)\n\n        # Etapa 7: Comparar modelos\n        self.comparar_modelos()\n\n        # Etapa 8: Analisar importância de features\n        self.analisar_importancia_features()\n\n        # Etapa 9: Extrair regras da Decision Tree\n        self.extrair_regras_decision_tree()\n\n        # Etapa 10: Gerar exemplos práticos\n        self.gerar_exemplos_praticos()\n\n        print(\"\\n===== Pipeline Completo Finalizado =====\")\n        print(f\"Todos os modelos e resultados foram salvos no diretório: {OUTPUT_DIR}\")\n        print(f\"Todas as visualizações foram salvas no diretório: {FIGURES_DIR}\")\n\n        # Retornar informações sobre o melhor modelo\n        return {\n            'best_model_name': self.best_model_name,\n            'best_model_performance': self.results[self.best_model_name],\n            'feature_names': self.feature_names,\n            'target_mapping': self.target_mapping\n        }\n\ndef criar_app_predicao(pipeline):\n    \"\"\"\n    Cria um aplicativo simples para previsão interativa\n    \"\"\"\n    print(\"\\n===== Criando Aplicativo de Previsão =====\")\n\n    # Extrair informações necessárias\n    if not pipeline.best_model:\n        print(\"Nenhum modelo treinado disponível.\")\n        return\n\n    # Verificar se pipeline possui informações necessárias\n    if not hasattr(pipeline, 'feature_names') or not hasattr(pipeline, 'target_mapping'):\n        print(\"Informações necessárias não encontradas no pipeline.\")\n        return\n\n    # Criar arquivo Python com aplicativo de previsão\n    app_code = f\"\"\"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n'''\n/fiap/cap14/app_predicao.py\n\nAplicativo simples para prever a cultura ideal com base em condições de solo e clima\n'''\n\nimport joblib\nimport numpy as np\nimport argparse\nimport sys\nfrom pathlib import Path\n\n# Carregar modelo\nMODEL_PATH = Path('{OUTPUT_DIR}/{pipeline.best_model_name.replace(\" \", \"_\").lower()}_best_model.pkl')\nmodelo = joblib.load(MODEL_PATH)\n\n# Definir nomes das features e mapeamento de classes\nfeature_names = {pipeline.feature_names}\ntarget_mapping = {pipeline.target_mapping}\n\ndef prever_cultura(valores):\n    '''\n    Prevê a cultura ideal com base nos valores informados\n\n    Parâmetros:\n    valores (list): Lista com os valores na ordem: {', '.join([str(f) for f in pipeline.feature_names])}\n\n    Retorna:\n    dict: Dicionário com a cultura prevista e confiança (se disponível)\n    '''\n    # Converter entrada para array numpy\n    X = np.array(valores).reshape(1, -1)\n\n    # Fazer previsão\n    y_pred = modelo.predict(X)[0]\n    cultura = target_mapping.get(y_pred, \"Desconhecida\")\n\n    # Tentar obter probabilidades (se o modelo suportar)\n    confianca = None\n    try:\n        if hasattr(modelo, 'predict_proba'):\n            proba = modelo.predict_proba(X)\n            confianca = float(np.max(proba))\n    except:\n        pass\n\n    return {{\n        'cultura': cultura,\n        'confianca': confianca\n    }}\n\ndef exemplo_interativo():\n    '''\n    Executa um exemplo interativo de previsão\n    '''\n    print(\"\\\\n===== Sistema de Previsão de Cultura Ideal =====\")\n    print(f\"Utilizando o modelo: {{MODEL_PATH.name}}\")\n    print(\"\\\\nDigite os valores para as seguintes condições:\")\n\n    valores = []\n\n    for feature in feature_names:\n        while True:\n            try:\n                valor = float(input(f\"{{feature}}: \"))\n                valores.append(valor)\n                break\n            except ValueError:\n                print(\"Por favor, digite um valor numérico válido.\")\n\n    resultado = prever_cultura(valores)\n\n    print(\"\\\\n----- Resultado -----\")\n    print(f\"Cultura ideal prevista: {{resultado['cultura']}}\")\n\n    if resultado['confianca']:\n        print(f\"Confiança da previsão: {{resultado['confianca']:.2f}}\")\n\n    print(\"\\\\nObservação: Este é um modelo experimental e os resultados devem ser\")\n    print(\"validados por especialistas em agricultura antes de aplicação prática.\")\n\ndef modo_nao_interativo(valores):\n    '''\n    Executa o modelo em modo não-interativo\n\n    Parâmetros:\n    valores (list): Lista com os valores na ordem: {', '.join([str(f) for f in pipeline.feature_names])}\n    '''\n    if len(valores) != len(feature_names):\n        print(f\"Erro: Número incorreto de valores. Esperado {{len(feature_names)}} valores.\")\n        print(f\"Ordem dos valores: {{', '.join(feature_names)}}\")\n        sys.exit(1)\n\n    try:\n        # Converter para float\n        valores_float = [float(v) for v in valores]\n\n        # Fazer previsão\n        resultado = prever_cultura(valores_float)\n\n        print(\"\\\\n----- Resultado -----\")\n        print(f\"Cultura ideal prevista: {{resultado['cultura']}}\")\n\n        if resultado['confianca']:\n            print(f\"Confiança da previsão: {{resultado['confianca']:.2f}}\")\n\n        return resultado\n    except ValueError as e:\n        print(f\"Erro ao converter valores: {{e}}\")\n        sys.exit(1)\n\ndef usar_exemplo_real():\n    '''\n    Usa um exemplo real do conjunto de dados para demonstração\n    '''\n    # Carregar dataset original\n    try:\n        import pandas as pd\n        DATA_DIR = Path('fase3_cap14/src/datasets/')\n        DATASET_PATH = DATA_DIR / 'Atividade_Cap_14_produtos_agricolas.csv'\n        df = pd.read_csv(DATASET_PATH)\n\n        # Selecionar uma amostra aleatória\n        amostra = df.sample(n=1, random_state=42)\n\n        # Extrair valores das features\n        valores = amostra.drop('label', axis=1).values[0].tolist()\n        cultura_real = amostra['label'].values[0]\n\n        # Fazer previsão\n        resultado = prever_cultura(valores)\n\n        print(\"\\\\n===== Exemplo com Dados Reais =====\")\n        print(\"\\\\nValores das características:\")\n        for i, feat in enumerate(feature_names):\n            print(f\"  {{feat}}: {{valores[i]:.2f}}\")\n\n        print(\"\\\\n----- Resultado -----\")\n        print(f\"Cultura real: {{cultura_real}}\")\n        print(f\"Cultura prevista: {{resultado['cultura']}}\")\n\n        if resultado['confianca']:\n            print(f\"Confiança da previsão: {{resultado['confianca']:.2f}}\")\n\n        print(f\"Previsão correta: {{cultura_real == resultado['cultura']}}\")\n\n        return resultado\n    except Exception as e:\n        print(f\"Erro ao usar exemplo real: {{e}}\")\n        return None\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='Previsão de cultura agrícola ideal')\n    parser.add_argument('--valores', nargs='+', help=f\"Valores das características na ordem: {{', '.join(feature_names)}}\")\n    parser.add_argument('--exemplo-real', action='store_true', help='Usar um exemplo real do conjunto de dados')\n\n    args = parser.parse_args()\n\n    if args.exemplo_real:\n        # Usar exemplo real do dataset\n        usar_exemplo_real()\n    elif args.valores:\n        # Modo não-interativo com valores fornecidos\n        modo_nao_interativo(args.valores)\n    else:\n        # Modo interativo\n        exemplo_interativo()\n\"\"\"\n\n    # Salvar o aplicativo\n    app_path = (Path(DATA_DIR) / 'output' / 'modelos_preditivos' / 'utils' / 'app_predicao.py').resolve()\n    app_path.parent.mkdir(parents=True, exist_ok=True)\n    with open(app_path, 'w') as f:\n        f.write(app_code)\n\n    print(f\"Aplicativo de previsão criado em: {app_path}\")\n    print(\"Para usar o aplicativo, execute para obter informações: python app_predicao.py -h\")\n\n    return app_path\n\ndef main():\n    \"\"\"\n    Função principal para execução do pipeline ML\n    \"\"\"\n    print(\"===== Iniciando Desenvolvimento de Modelos Preditivos =====\")\n\n    # Criar e executar pipeline\n    pipeline = AgricultureMLPipeline()\n    resultados = pipeline.executar_pipeline_completo()\n\n    # Criar aplicativo de previsão\n    criar_app_predicao(pipeline)\n\n    return resultados\n\nif __name__ == \"__main__\":\n    main()\n",
            "block_group": "483e18ab5afd4061bf1a71a9f8e82962",
            "execution_count": 1,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "===== Iniciando Desenvolvimento de Modelos Preditivos =====\n\n===== Iniciando Pipeline Completo de ML =====\nDataset carregado com sucesso: 2200 linhas e 8 colunas\n\n===== Exploração dos Dados =====\n\nInformações do dataset:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2200 entries, 0 to 2199\nData columns (total 8 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   N            2200 non-null   int64  \n 1   P            2200 non-null   int64  \n 2   K            2200 non-null   int64  \n 3   temperature  2200 non-null   float64\n 4   humidity     2200 non-null   float64\n 5   ph           2200 non-null   float64\n 6   rainfall     2200 non-null   float64\n 7   label        2200 non-null   object \ndtypes: float64(4), int64(3), object(1)\nmemory usage: 137.6+ KB\nNone\n\nEstatísticas descritivas:\n                 N            P            K  temperature     humidity  \\\ncount  2200.000000  2200.000000  2200.000000  2200.000000  2200.000000   \nmean     50.551818    53.362727    48.149091    25.616244    71.481779   \nstd      36.917334    32.985883    50.647931     5.063749    22.263812   \nmin       0.000000     5.000000     5.000000     8.825675    14.258040   \n25%      21.000000    28.000000    20.000000    22.769375    60.261953   \n50%      37.000000    51.000000    32.000000    25.598693    80.473146   \n75%      84.250000    68.000000    49.000000    28.561654    89.948771   \nmax     140.000000   145.000000   205.000000    43.675493    99.981876   \n\n                ph     rainfall  \ncount  2200.000000  2200.000000  \nmean      6.469480   103.463655  \nstd       0.773938    54.958389  \nmin       3.504752    20.211267  \n25%       5.971693    64.551686  \n50%       6.425045    94.867624  \n75%       6.923643   124.267508  \nmax       9.935091   298.560117  \n\nNão foram encontrados valores ausentes no dataset.\n\nDistribuição da variável alvo (culturas):\nlabel\nrice           100\nmaize          100\njute           100\ncotton         100\ncoconut        100\npapaya         100\norange         100\napple          100\nmuskmelon      100\nwatermelon     100\ngrapes         100\nmango          100\nbanana         100\npomegranate    100\nlentil         100\nblackgram      100\nmungbean       100\nmothbeans      100\npigeonpeas     100\nkidneybeans    100\nchickpea       100\ncoffee         100\nName: count, dtype: int64\n\nNúmero total de classes: 22\nClasse mais frequente: rice (100 ocorrências)\nClasse menos frequente: coffee (100 ocorrências)\n\n===== Pré-processamento dos Dados =====\nDados divididos em 1760 amostras de treino e 440 amostras de teste\nFeatures normalizadas utilizando StandardScaler\nDistribuição de classes no conjunto de treino: Min=80, Max=80\nDistribuição de classes no conjunto de teste: Min=20, Max=20\n\n===== Treinamento dos Modelos =====\n\nTreinando modelo: Decision Tree\nModelo Decision Tree treinado em 0.01 segundos\n\nTreinando modelo: Random Forest\nModelo Random Forest treinado em 0.25 segundos\n\nTreinando modelo: SVM\nModelo SVM treinado em 0.15 segundos\n\nTreinando modelo: KNN\nModelo KNN treinado em 0.00 segundos\n\nTreinando modelo: Gradient Boosting\nModelo Gradient Boosting treinado em 7.51 segundos\n\n===== Otimização de Hiperparâmetros =====\n\nOtimizando hiperparâmetros para: Decision Tree\nFitting 5 folds for each of 72 candidates, totalling 360 fits\nMelhores parâmetros para Decision Tree: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}\nMelhor score de validação cruzada: 0.9852\nTempo de otimização: 1.81 segundos\n\nOtimizando hiperparâmetros para: Random Forest\nFitting 5 folds for each of 108 candidates, totalling 540 fits\nMelhores parâmetros para Random Forest: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\nMelhor score de validação cruzada: 0.9960\nTempo de otimização: 12.94 segundos\n\nOtimizando hiperparâmetros para: SVM\nFitting 5 folds for each of 32 candidates, totalling 160 fits\nMelhores parâmetros para SVM: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\nMelhor score de validação cruzada: 0.9869\nTempo de otimização: 2.52 segundos\n\nOtimizando hiperparâmetros para: KNN\nFitting 5 folds for each of 20 candidates, totalling 100 fits\nMelhores parâmetros para KNN: {'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\nMelhor score de validação cruzada: 0.9812\nTempo de otimização: 0.14 segundos\n\nOtimizando hiperparâmetros para: Gradient Boosting\nFitting 5 folds for each of 54 candidates, totalling 270 fits\nMelhores parâmetros para Gradient Boosting: {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 200}\nMelhor score de validação cruzada: 0.9886\nTempo de otimização: 203.34 segundos\n\n===== Avaliação dos Modelos =====\n\nAvaliando modelo: Decision Tree\nAcurácia: 0.9795\nAcurácia Balanceada: 0.9795\nPrecisão: 0.9806\nRecall: 0.9795\nF1-Score: 0.9794\nCoeficiente de Matthews: 0.9786\nTempo de inferência: 0.000557 segundos\n\nRelatório de classificação detalhado:\n              precision    recall  f1-score   support\n\n       apple       1.00      1.00      1.00        20\n      banana       1.00      1.00      1.00        20\n   blackgram       1.00      0.80      0.89        20\n    chickpea       1.00      1.00      1.00        20\n     coconut       1.00      1.00      1.00        20\n      coffee       1.00      1.00      1.00        20\n      cotton       1.00      1.00      1.00        20\n      grapes       1.00      1.00      1.00        20\n        jute       0.95      0.95      0.95        20\n kidneybeans       1.00      1.00      1.00        20\n      lentil       0.86      0.90      0.88        20\n       maize       0.95      1.00      0.98        20\n       mango       1.00      1.00      1.00        20\n   mothbeans       0.86      0.95      0.90        20\n    mungbean       1.00      1.00      1.00        20\n   muskmelon       1.00      1.00      1.00        20\n      orange       1.00      1.00      1.00        20\n      papaya       1.00      1.00      1.00        20\n  pigeonpeas       1.00      1.00      1.00        20\n pomegranate       1.00      1.00      1.00        20\n        rice       0.95      0.95      0.95        20\n  watermelon       1.00      1.00      1.00        20\n\n    accuracy                           0.98       440\n   macro avg       0.98      0.98      0.98       440\nweighted avg       0.98      0.98      0.98       440\n\n\nAvaliando modelo: Random Forest\nAcurácia: 0.9955\nAcurácia Balanceada: 0.9955\nPrecisão: 0.9957\nRecall: 0.9955\nF1-Score: 0.9955\nCoeficiente de Matthews: 0.9952\nTempo de inferência: 0.009873 segundos\n\nRelatório de classificação detalhado:\n              precision    recall  f1-score   support\n\n       apple       1.00      1.00      1.00        20\n      banana       1.00      1.00      1.00        20\n   blackgram       1.00      0.95      0.97        20\n    chickpea       1.00      1.00      1.00        20\n     coconut       1.00      1.00      1.00        20\n      coffee       1.00      1.00      1.00        20\n      cotton       1.00      1.00      1.00        20\n      grapes       1.00      1.00      1.00        20\n        jute       0.95      1.00      0.98        20\n kidneybeans       1.00      1.00      1.00        20\n      lentil       1.00      1.00      1.00        20\n       maize       0.95      1.00      0.98        20\n       mango       1.00      1.00      1.00        20\n   mothbeans       1.00      1.00      1.00        20\n    mungbean       1.00      1.00      1.00        20\n   muskmelon       1.00      1.00      1.00        20\n      orange       1.00      1.00      1.00        20\n      papaya       1.00      1.00      1.00        20\n  pigeonpeas       1.00      1.00      1.00        20\n pomegranate       1.00      1.00      1.00        20\n        rice       1.00      0.95      0.97        20\n  watermelon       1.00      1.00      1.00        20\n\n    accuracy                           1.00       440\n   macro avg       1.00      1.00      1.00       440\nweighted avg       1.00      1.00      1.00       440\n\n\nAvaliando modelo: SVM\nAcurácia: 0.9886\nAcurácia Balanceada: 0.9886\nPrecisão: 0.9894\nRecall: 0.9886\nF1-Score: 0.9886\nCoeficiente de Matthews: 0.9881\nTempo de inferência: 0.012441 segundos\n\nRelatório de classificação detalhado:\n              precision    recall  f1-score   support\n\n       apple       1.00      1.00      1.00        20\n      banana       1.00      1.00      1.00        20\n   blackgram       0.95      1.00      0.98        20\n    chickpea       1.00      1.00      1.00        20\n     coconut       1.00      1.00      1.00        20\n      coffee       1.00      1.00      1.00        20\n      cotton       0.95      1.00      0.98        20\n      grapes       1.00      1.00      1.00        20\n        jute       0.91      1.00      0.95        20\n kidneybeans       1.00      1.00      1.00        20\n      lentil       0.95      1.00      0.98        20\n       maize       1.00      0.95      0.97        20\n       mango       1.00      1.00      1.00        20\n   mothbeans       1.00      0.95      0.97        20\n    mungbean       1.00      1.00      1.00        20\n   muskmelon       1.00      1.00      1.00        20\n      orange       1.00      1.00      1.00        20\n      papaya       1.00      1.00      1.00        20\n  pigeonpeas       1.00      0.95      0.97        20\n pomegranate       1.00      1.00      1.00        20\n        rice       1.00      0.90      0.95        20\n  watermelon       1.00      1.00      1.00        20\n\n    accuracy                           0.99       440\n   macro avg       0.99      0.99      0.99       440\nweighted avg       0.99      0.99      0.99       440\n\n\nAvaliando modelo: KNN\nAcurácia: 0.9818\nAcurácia Balanceada: 0.9818\nPrecisão: 0.9823\nRecall: 0.9818\nF1-Score: 0.9817\nCoeficiente de Matthews: 0.9810\nTempo de inferência: 0.005153 segundos\n\nRelatório de classificação detalhado:\n              precision    recall  f1-score   support\n\n       apple       1.00      1.00      1.00        20\n      banana       1.00      1.00      1.00        20\n   blackgram       1.00      1.00      1.00        20\n    chickpea       1.00      1.00      1.00        20\n     coconut       0.95      1.00      0.98        20\n      coffee       1.00      1.00      1.00        20\n      cotton       0.95      1.00      0.98        20\n      grapes       1.00      1.00      1.00        20\n        jute       0.95      1.00      0.98        20\n kidneybeans       0.95      1.00      0.98        20\n      lentil       0.95      0.95      0.95        20\n       maize       1.00      0.95      0.97        20\n       mango       0.95      1.00      0.98        20\n   mothbeans       0.95      0.90      0.92        20\n    mungbean       1.00      1.00      1.00        20\n   muskmelon       1.00      1.00      1.00        20\n      orange       1.00      0.90      0.95        20\n      papaya       1.00      1.00      1.00        20\n  pigeonpeas       1.00      0.95      0.97        20\n pomegranate       0.95      1.00      0.98        20\n        rice       1.00      0.95      0.97        20\n  watermelon       1.00      1.00      1.00        20\n\n    accuracy                           0.98       440\n   macro avg       0.98      0.98      0.98       440\nweighted avg       0.98      0.98      0.98       440\n\n\nAvaliando modelo: Gradient Boosting\nAcurácia: 0.9864\nAcurácia Balanceada: 0.9864\nPrecisão: 0.9867\nRecall: 0.9864\nF1-Score: 0.9864\nCoeficiente de Matthews: 0.9857\nTempo de inferência: 0.012940 segundos\n\nRelatório de classificação detalhado:\n              precision    recall  f1-score   support\n\n       apple       1.00      1.00      1.00        20\n      banana       1.00      1.00      1.00        20\n   blackgram       0.95      0.95      0.95        20\n    chickpea       1.00      1.00      1.00        20\n     coconut       1.00      1.00      1.00        20\n      coffee       1.00      1.00      1.00        20\n      cotton       1.00      1.00      1.00        20\n      grapes       1.00      1.00      1.00        20\n        jute       0.90      0.95      0.93        20\n kidneybeans       1.00      1.00      1.00        20\n      lentil       1.00      0.95      0.97        20\n       maize       0.95      1.00      0.98        20\n       mango       1.00      1.00      1.00        20\n   mothbeans       0.95      1.00      0.98        20\n    mungbean       1.00      1.00      1.00        20\n   muskmelon       1.00      1.00      1.00        20\n      orange       1.00      1.00      1.00        20\n      papaya       1.00      1.00      1.00        20\n  pigeonpeas       1.00      0.95      0.97        20\n pomegranate       1.00      1.00      1.00        20\n        rice       0.95      0.90      0.92        20\n  watermelon       1.00      1.00      1.00        20\n\n    accuracy                           0.99       440\n   macro avg       0.99      0.99      0.99       440\nweighted avg       0.99      0.99      0.99       440\n\n\nMelhor modelo: Random Forest\nF1-Score: 0.9955\n\n===== Comparação de Modelos =====\n\nTabela comparativa de modelos:\n                      Decision Tree  Random Forest       SVM       KNN  \\\nAcurácia                   0.979545       0.995455  0.988636  0.981818   \nAcurácia Balanceada        0.979545       0.995455  0.988636  0.981818   \nPrecisão                   0.980598       0.995671  0.989374  0.982348   \nRecall                     0.979545       0.995455  0.988636  0.981818   \nF1-Score                   0.979423       0.995452  0.988621  0.981690   \nCoef. Matthews             0.978630       0.995249  0.988133  0.980990   \nTempo Inferência (s)       0.000557       0.009873  0.012441  0.005153   \n\n                      Gradient Boosting  \nAcurácia                       0.986364  \nAcurácia Balanceada            0.986364  \nPrecisão                       0.986677  \nRecall                         0.986364  \nF1-Score                       0.986357  \nCoef. Matthews                 0.985730  \nTempo Inferência (s)           0.012940  \n\n===== Análise de Importância de Features =====\n\nImportância de features para Decision Tree:\n  rainfall: 0.3196\n  P: 0.2251\n  humidity: 0.1984\n  N: 0.1444\n  K: 0.0977\n  ph: 0.0074\n  temperature: 0.0073\n\nImportância de features para Random Forest:\n  rainfall: 0.2231\n  humidity: 0.2169\n  K: 0.1834\n  P: 0.1456\n  N: 0.1020\n  temperature: 0.0755\n  ph: 0.0535\n\nImportância de features para Gradient Boosting:\n  rainfall: 0.2533\n  humidity: 0.1943\n  K: 0.1721\n  P: 0.1599\n  N: 0.1188\n  ph: 0.0509\n  temperature: 0.0508\n/tmp/ipykernel_37/3166917247.py:547: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(\n/tmp/ipykernel_37/3166917247.py:547: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(\n/tmp/ipykernel_37/3166917247.py:547: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(\n\n===== Extração de Regras da Decision Tree =====\n\nRegras extraídas da Decision Tree (limitadas à profundidade 3):\n|--- rainfall <= -1.33\n|   |--- class: 15\n|--- rainfall >  -1.33\n|   |--- humidity <= -1.95\n|   |   |--- K <= 0.04\n|   |   |   |--- class: 9\n|   |   |--- K >  0.04\n|   |   |   |--- class: 3\n|   |--- humidity >  -1.95\n|   |   |--- P <= 1.64\n|   |   |   |--- humidity <= -0.03\n|   |   |   |   |--- truncated branch of depth 8\n|   |   |   |--- humidity >  -0.03\n|   |   |   |   |--- truncated branch of depth 13\n|   |   |--- P >  1.64\n|   |   |   |--- humidity <= 0.70\n|   |   |   |   |--- class: 7\n|   |   |   |--- humidity >  0.70\n|   |   |   |   |--- class: 0\n\n\n===== Exemplos Práticos de Previsões =====\n\nExemplos de previsões utilizando o modelo Random Forest:\n\nExemplo 1:\n  N: -0.96\n  P: 0.02\n  K: -0.65\n  temperature: 0.86\n  humidity: -0.65\n  ph: 2.40\n  rainfall: -1.07\n  Cultura real: mothbeans\n  Cultura prevista: mothbeans\n  Confiança da previsão: 0.93\n  Previsão correta: Sim\n\nExemplo 2:\n  N: -0.80\n  P: -0.47\n  K: -0.54\n  temperature: 0.82\n  humidity: 0.67\n  ph: 0.21\n  rainfall: -1.20\n  Cultura real: mungbean\n  Cultura prevista: mungbean\n  Confiança da previsão: 0.98\n  Previsão correta: Sim\n\nExemplo 3:\n  N: -0.86\n  P: 0.75\n  K: -0.63\n  temperature: -0.98\n  humidity: -2.17\n  ph: -0.65\n  rainfall: -0.65\n  Cultura real: kidneybeans\n  Cultura prevista: kidneybeans\n  Confiança da previsão: 0.97\n  Previsão correta: Sim\n\nExemplo 4:\n  N: -0.34\n  P: -0.98\n  K: -0.26\n  temperature: -1.04\n  humidity: 0.81\n  ph: -0.81\n  rainfall: 0.14\n  Cultura real: pomegranate\n  Cultura prevista: pomegranate\n  Confiança da previsão: 0.92\n  Previsão correta: Sim\n\nExemplo 5:\n  N: -0.99\n  P: -1.04\n  K: -0.67\n  temperature: -1.56\n  humidity: 1.03\n  ph: 0.29\n  rainfall: 0.08\n  Cultura real: orange\n  Cultura prevista: orange\n  Confiança da previsão: 0.96\n  Previsão correta: Sim\n\n===== Pipeline Completo Finalizado =====\nTodos os modelos e resultados foram salvos no diretório: fase3_cap14/src/datasets/output/modelos_preditivos/modelos\nTodas as visualizações foram salvas no diretório: fase3_cap14/src/datasets/output/modelos_preditivos/figuras\n\n===== Criando Aplicativo de Previsão =====\nAplicativo de previsão criado em: {app_path}\nPara usar o aplicativo, execute: python app_predicao.py\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "s3:deepnote-cell-outputs-production/7fcce70e-05f0-4b4b-9389-f80ef43af5db",
            "content_dependencies": {
                "codeHash": "5d166330",
                "usedVariables": [
                    "DecisionTreeClassifier",
                    "np",
                    "plt",
                    "pipeline",
                    "app_code",
                    "f",
                    "main",
                    "KNeighborsClassifier",
                    "SVC",
                    "resultados",
                    "Path",
                    "GradientBoostingClassifier",
                    "DATA_DIR",
                    "criar_app_predicao",
                    "app_path",
                    "RANDOM_STATE",
                    "OUTPUT_DIR",
                    "FIGURES_DIR",
                    "RandomForestClassifier",
                    "sns",
                    "AgricultureMLPipeline"
                ],
                "importedModules": [
                    "accuracy_score",
                    "DecisionTreeClassifier",
                    "np",
                    "mpatches",
                    "matthews_corrcoef",
                    "plt",
                    "f1_score",
                    "KNeighborsClassifier",
                    "SVC",
                    "balanced_accuracy_score",
                    "Path",
                    "GradientBoostingClassifier",
                    "Pipeline",
                    "LinearSegmentedColormap",
                    "recall_score",
                    "LabelEncoder",
                    "GridSearchCV",
                    "joblib",
                    "confusion_matrix",
                    "gridspec",
                    "classification_report",
                    "cross_val_score",
                    "train_test_split",
                    "StandardScaler",
                    "pd",
                    "RandomForestClassifier",
                    "sns",
                    "precision_score",
                    "time"
                ],
                "definedVariables": [
                    "f",
                    "main",
                    "AgricultureMLPipeline",
                    "FIGURES_DIR",
                    "pipeline",
                    "resultados",
                    "MODELOS",
                    "DATA_DIR",
                    "criar_app_predicao",
                    "app_code",
                    "app_path",
                    "RANDOM_STATE",
                    "OUTPUT_DIR",
                    "CUSTOM_COLORS",
                    "DATASET_PATH"
                ]
            }
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "33f8812c",
                "execution_start": 1747950696017,
                "execution_millis": 1329,
                "execution_context_id": "c1006344-f174-4a4c-a97c-86efdada21e1",
                "cell_id": "dd2d217a499244efab1e3e3d55b622d1",
                "deepnote_cell_type": "code"
            },
            "source": "!python3 fase3_cap14/src/datasets/output/modelos_preditivos/utils/app_predicao.py --valores 90 42 43 20.87 82.18 6.5 202.9",
            "block_group": "ea8c7445a1fd498abb3fbe74e7c93aa6",
            "execution_count": 64,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "\n----- Resultado -----\nCultura ideal prevista: apple\nConfiança da previsão: 0.42\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "dbtable:cell_outputs/c14f93a1-7530-4527-8bae-810c077c4c26",
            "content_dependencies": {
                "codeHash": "33f8812c",
                "usedVariables": [],
                "importedModules": [],
                "definedVariables": []
            }
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "933f597f",
                "execution_start": 1747950797563,
                "execution_millis": 1308,
                "execution_context_id": "c1006344-f174-4a4c-a97c-86efdada21e1",
                "cell_id": "6693183ae26b4fb09e38758af5499f42",
                "deepnote_cell_type": "code"
            },
            "source": "!python3 fase3_cap14/src/datasets/output/modelos_preditivos/utils/app_predicao.py -h",
            "block_group": "d1a490eb4b6641f89eb23f146c71077f",
            "execution_count": 70,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "usage: app_predicao.py [-h] [--valores VALORES [VALORES ...]] [--exemplo-real]\n\nPrevisão de cultura agrícola ideal\n\noptions:\n  -h, --help            show this help message and exit\n  --valores VALORES [VALORES ...]\n                        Valores das características na ordem: N, P, K,\n                        temperature, humidity, ph, rainfall\n  --exemplo-real        Usar um exemplo real do conjunto de dados\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "dbtable:cell_outputs/a0062c6a-e8af-4e02-9e6b-2776593dd511",
            "content_dependencies": {
                "codeHash": "7b06ddde",
                "usedVariables": [],
                "importedModules": [],
                "definedVariables": []
            }
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "7b06ddde",
                "execution_start": 1747950828657,
                "execution_millis": 1875,
                "execution_context_id": "c1006344-f174-4a4c-a97c-86efdada21e1",
                "cell_id": "44ff8fef3c5c4ed789217fc67b254ce4",
                "deepnote_cell_type": "code"
            },
            "source": "!python3 fase3_cap14/src/datasets/output/modelos_preditivos/utils/app_predicao.py --exemplo-real",
            "block_group": "4e38d1d8758e4136975c25dc98bbe2f9",
            "execution_count": 73,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "\n===== Exemplo com Dados Reais =====\n\nValores das características:\n  N: 101.00\n  P: 17.00\n  K: 47.00\n  temperature: 29.49\n  humidity: 94.73\n  ph: 6.19\n  rainfall: 26.31\n\n----- Resultado -----\nCultura real: muskmelon\nCultura prevista: apple\nConfiança da previsão: 0.42\nPrevisão correta: False\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "dbtable:cell_outputs/0ec6265f-8554-4eb6-9950-7ebf1d6c55b2",
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "815b4dd3",
                "execution_start": 1747950402127,
                "execution_millis": 333,
                "execution_context_id": "c1006344-f174-4a4c-a97c-86efdada21e1",
                "cell_id": "23c93a8394704472bd20a880f24ef0e9",
                "deepnote_cell_type": "code"
            },
            "source": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n'''\nADAPTADO PARA EXECUÇÃO EM CÉLULA\n\n/fiap/cap14/app_predicao.py\nAplicativo simples para prever a cultura ideal com base em condições de solo e clima\n'''\n\nimport joblib\nimport numpy as np\nimport argparse\nimport sys\nfrom pathlib import Path\n\n# Carregar modelo\nMODEL_PATH = Path('fase3_cap14/src/datasets/output/modelos_preditivos/modelos/random_forest_best_model.pkl')\nmodelo = joblib.load(MODEL_PATH)\n\n# Definir nomes das features e mapeamento de classes\nfeature_names = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\ntarget_mapping = {0: 'apple', 1: 'banana', 2: 'blackgram', 3: 'chickpea', 4: 'coconut', 5: 'coffee', 6: 'cotton', 7: 'grapes', 8: 'jute', 9: 'kidneybeans', 10: 'lentil', 11: 'maize', 12: 'mango', 13: 'mothbeans', 14: 'mungbean', 15: 'muskmelon', 16: 'orange', 17: 'papaya', 18: 'pigeonpeas', 19: 'pomegranate', 20: 'rice', 21: 'watermelon'}\n\ndef prever_cultura(valores):\n    '''\n    Prevê a cultura ideal com base nos valores informados\n\n    Parâmetros:\n    valores (list): Lista com os valores na ordem: N, P, K, temperature, humidity, ph, rainfall\n\n    Retorna:\n    dict: Dicionário com a cultura prevista e confiança (se disponível)\n    '''\n    # Converter entrada para array numpy\n    X = np.array(valores).reshape(1, -1)\n\n    # Fazer previsão\n    y_pred = modelo.predict(X)[0]\n    cultura = target_mapping.get(y_pred, \"Desconhecida\")\n\n    # Tentar obter probabilidades (se o modelo suportar)\n    confianca = None\n    try:\n        if hasattr(modelo, 'predict_proba'):\n            proba = modelo.predict_proba(X)\n            confianca = float(np.max(proba))\n    except:\n        pass\n\n    return {\n        'cultura': cultura,\n        'confianca': confianca\n    }\n\ndef exemplo_interativo():\n    '''\n    Executa um exemplo interativo de previsão\n    '''\n    print(\"\\n===== Sistema de Previsão de Cultura Ideal =====\")\n    print(f\"Utilizando o modelo: {MODEL_PATH.name}\")\n    print(\"\\nDigite os valores para as seguintes condições:\")\n\n    valores = []\n\n    for feature in feature_names:\n        while True:\n            try:\n                valor = float(input(f\"{feature}: \"))\n                valores.append(valor)\n                break\n            except ValueError:\n                print(\"Por favor, digite um valor numérico válido.\")\n\n    resultado = prever_cultura(valores)\n\n    print(\"\\n----- Resultado -----\")\n    print(f\"Cultura ideal prevista: {resultado['cultura']}\")\n\n    if resultado['confianca']:\n        print(f\"Confiança da previsão: {resultado['confianca']:.2f}\")\n\n    print(\"\\nObservação: Este é um modelo experimental e os resultados devem ser\")\n    print(\"validados por especialistas em agricultura antes de aplicação prática.\")\n\ndef modo_nao_interativo(valores):\n    '''\n    Executa o modelo em modo não-interativo\n\n    Parâmetros:\n    valores (list): Lista com os valores na ordem: N, P, K, temperature, humidity, ph, rainfall\n    '''\n    if len(valores) != len(feature_names):\n        print(f\"Erro: Número incorreto de valores. Esperado {len(feature_names)} valores.\")\n        print(f\"Ordem dos valores: {', '.join(feature_names)}\")\n        sys.exit(1)\n\n    try:\n        # Converter para float\n        valores_float = [float(v) for v in valores]\n\n        # Fazer previsão\n        resultado = prever_cultura(valores_float)\n\n        print(\"\\n----- Resultado -----\")\n        print(f\"Cultura ideal prevista: {resultado['cultura']}\")\n\n        if resultado['confianca']:\n            print(f\"Confiança da previsão: {resultado['confianca']:.2f}\")\n\n        return resultado\n    except ValueError as e:\n        print(f\"Erro ao converter valores: {e}\")\n        sys.exit(1)\n\ndef usar_exemplo_real():\n    '''\n    Usa um exemplo real do conjunto de dados para demonstração\n    '''\n    # Carregar dataset original\n    try:\n        import pandas as pd\n        DATA_DIR = Path('fase3_cap14/src/datasets/')\n        DATASET_PATH = DATA_DIR / 'Atividade_Cap_14_produtos_agricolas.csv'\n        df = pd.read_csv(DATASET_PATH)\n\n        # Selecionar uma amostra aleatória\n        amostra = df.sample(n=1, random_state=42)\n\n        # Extrair valores das features\n        valores = amostra.drop('label', axis=1).values[0].tolist()\n        cultura_real = amostra['label'].values[0]\n\n        # Fazer previsão\n        resultado = prever_cultura(valores)\n\n        print(\"\\n===== Exemplo com Dados Reais =====\")\n        print(\"\\nValores das características:\")\n        for i, feat in enumerate(feature_names):\n            print(f\"  {feat}: {valores[i]:.2f}\")\n\n        print(\"\\n----- Resultado -----\")\n        print(f\"Cultura real: {cultura_real}\")\n        print(f\"Cultura prevista: {resultado['cultura']}\")\n\n        if resultado['confianca']:\n            print(f\"Confiança da previsão: {resultado['confianca']:.2f}\")\n\n        print(f\"Previsão correta: {cultura_real == resultado['cultura']}\")\n\n        return resultado\n    except Exception as e:\n        print(f\"Erro ao usar exemplo real: {e}\")\n        return None\n\nif __name__ == \"__main__\":\n    usar_exemplo_real()\n",
            "block_group": "531f34bd5e224808981d41fd2ee0fba3",
            "execution_count": 55,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "\n===== Exemplo com Dados Reais =====\n\nValores das características:\n  N: 101.00\n  P: 17.00\n  K: 47.00\n  temperature: 29.49\n  humidity: 94.73\n  ph: 6.19\n  rainfall: 26.31\n\n----- Resultado -----\nCultura real: muskmelon\nCultura prevista: apple\nConfiança da previsão: 0.42\nPrevisão correta: False\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "dbtable:cell_outputs/b4c0cb0a-54ec-45cc-8daf-2fb888c402b2",
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b5dc9755-22da-4b0a-a5aa-ce1cc97fc743' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
            "metadata": {
                "created_in_deepnote_cell": true,
                "deepnote_cell_type": "markdown"
            }
        }
    ],
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "deepnote_persisted_session": {
            "createdAt": "2025-05-22T21:56:59.997Z"
        },
        "deepnote_notebook_id": "17c630b24d39484f95001d57dc9115fc"
    }
}